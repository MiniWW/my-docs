---
cover: /assets/images/cover2.jpg
icon: pen-to-square
date: 2024-05-09
category:
  - Java集合
tag:
  - 红
  - 圆
star: true
sticky: true
---



# HashMap
在 Java 中，当 HashMap 发生哈希冲突且数组长度小于64时，会先进行数组扩容。这是因为 HashMap 内部采用了一个称为负载因子（load factor）的概念来控制数组的扩容。负载因子是指哈希表中存储的元素数量与数组长度的比值，当这个比值超过了预设的阈值（通常为 0.75），HashMap 就会触发扩容操作，以保持哈希表的性能。

在进行扩容时，HashMap 会新建一个更大的数组，通常是原数组长度的两倍。然后，它会将原数组中的所有元素重新计算哈希值，并根据新的数组长度进行重新分配。这个过程称为重新哈希（rehashing）。重新哈希是一个相对耗时的操作，因为它涉及到对所有元素的重新计算哈希值和重新插入到新数组的过程。

需要注意的是，在进行扩容和重新哈希的过程中，HashMap 的线程安全性需要考虑。在多线程环境下，扩容和重新哈希过程可能会导致并发问题，因此在 Java 中，通常建议在多线程环境下使用 ConcurrentHashMap 来代替 HashMap，因为 ConcurrentHashMap 内置了更好的并发控制机制。



重新哈希是根据新的数组长度和元素的哈希值来进行的。通常，重新哈希会使用一个简单的模运算来确定元素应该插入到新数组的哪个位置。具体来说，对于每个元素的哈希值，重新哈希会使用以下公式：

\[ \text{newIndex} = \text{hash} \, \& \, (\text{newCapacity} - 1) \]

其中，\(\text{hash}\) 是元素的哈希值，\(\text{newCapacity}\) 是新数组的长度，\(\text{newIndex}\) 是元素在新数组中的索引位置。这个公式保证了元素被均匀地分布到新数组中的不同位置。

在进行扩容和重新哈希的过程中，可能会出现以下并发问题：

1. **竞态条件（Race Condition）**：如果在扩容过程中有其他线程同时对 HashMap 进行读或写操作，可能会导致竞态条件，使得其中一个线程的操作被覆盖或者产生错误的结果。

2. **数据丢失**：如果在扩容过程中有其他线程对 HashMap 进行写操作，而此时正在进行重新哈希操作，那么可能会导致一些元素没有被正确地插入到新数组中，从而导致数据丢失。

3. **迭代器失效**：在进行扩容和重新哈希的过程中，如果有其他线程正在使用迭代器遍历 HashMap，可能会导致迭代器失效或者抛出 ConcurrentModificationException 异常。

为了解决这些并发问题，Java 中的 HashMap 提供了一些线程安全的措施，比如使用 synchronized 关键字或者使用分段锁（在 ConcurrentHashMap 中）。另外，Java 8 引入了基于 CAS（Compare and Swap）操作的并发桶分割技术，进一步提高了并发性能。

